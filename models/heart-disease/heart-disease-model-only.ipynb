{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c6690e5-67ee-4ccf-87e0-3d5b7e5ac663",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Assignment for Week 2 - KNN\n",
    "- Get to know your data, start out by data exploration. Summarized your finding. \n",
    "- Divide the data into training set and test set randomly with ratio 80:20. Make prediction based on 1-nearest neighbor. What is the error rate of this approach? Report your results in a confusion matrix. \n",
    "- Use different values for K, what is the optimal value of K from your experiments? Report the error rate of the optimal K value and its confusion matrix. Is there any improvement (by how much) over 1-nearest neighbor? \n",
    "- Is there anything else you can do to improve your model? If yes, demonstrate your approach. (Hint: there is always something that you can try, unless your accuracy score is 100%) \n",
    " \n",
    "**Deliverables:**\n",
    "Upload your notebook's .ipynb file (Also, if you decide to use your heart_disease data set, I'll need a copy of that too. I can't validate your notebook without your dtatset.) \n",
    " \n",
    "> Important: Make sure your provide complete and thorough explanations for all of your analysis. You need to defend your thought processes and reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c1aa5f-fd5d-40db-82f9-541c4ec03874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, r2_score\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed30cb97-873d-4802-9310-3b357212e0e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 282 entries, 0 to 281\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       282 non-null    int64  \n",
      " 1   sex       282 non-null    int64  \n",
      " 2   cp        282 non-null    int64  \n",
      " 3   trestbps  282 non-null    int64  \n",
      " 4   chol      282 non-null    int64  \n",
      " 5   cigs      282 non-null    float64\n",
      " 6   years     282 non-null    float64\n",
      " 7   fbs       282 non-null    int64  \n",
      " 8   famhist   282 non-null    int64  \n",
      " 9   restecg   282 non-null    int64  \n",
      " 10  thalach   282 non-null    int64  \n",
      " 11  exang     282 non-null    int64  \n",
      " 12  thal      282 non-null    int64  \n",
      " 13  num       282 non-null    int64  \n",
      "dtypes: float64(2), int64(12)\n",
      "memory usage: 31.0 KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./heart.disease.data.clean.csv')\n",
    "df.info()\n",
    "df_clean = df.copy()\n",
    "df_clean.loc[df_clean['num'] > 0, 'num'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f98579ec-f033-40da-97a4-0f1356b4410d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selected predictors with abs corr >= .15\n",
    "target_col = 'num'\n",
    "feature_cols = ['age', 'sex', 'cp', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'thal'] # \n",
    "X = df_clean[feature_cols].values\n",
    "y = df_clean[target_col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4f22007-2a59-4253-9105-90d3f1fce6d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get training set of 20% \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalized data to improve accurracy\n",
    "sc_X = StandardScaler()\n",
    "# fit StandardScaler on entire dataset\n",
    "sc_X.fit(X)\n",
    "X_train = sc_X.transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76c65362-eada-49e7-9483-f5589adb1b8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80        29\n",
      "           1       0.81      0.75      0.78        28\n",
      "\n",
      "    accuracy                           0.79        57\n",
      "   macro avg       0.79      0.79      0.79        57\n",
      "weighted avg       0.79      0.79      0.79        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Results of best model\n",
    "k = 5\n",
    "classifier = KNeighborsClassifier(n_neighbors=k, n_jobs=-1)\n",
    "y_pred = classifier.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Compare best model against base line (k=1)\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7796ee81-c588-4c54-8143-13aaad754798",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "- Feature selection was made based on correlation matrix, including predictors with abs corr >= .15 only\n",
    "- As requested the training set used is 20% data set\n",
    "- As requested base line model fit was k=1\n",
    "- The final k parameter was choosed based on best model of the k=1..40\n",
    "- The selection criteria was the model with higher accuracy score, then lower False Negatives.\n",
    "- The model acurracy score was improved by 16.05% after normalizing the predictor values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0173605-3304-4c2e-a4b6-5a6e067a575d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['heart-disease.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "pipeline = Pipeline([('scaler', sc_X), ('classifier', classifier)])\n",
    "\n",
    "# save the model to disk\n",
    "joblib.dump(pipeline, 'heart-disease.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7eb9eb-0df6-47a6-a257-360ddae8431b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
